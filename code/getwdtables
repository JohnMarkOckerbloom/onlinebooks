#!/usr/bin/perl
use lib "nlib";
use WikidataQuerier;
use JSON;
use OLBP;

my $idxdir = "/mnt/onlinebooks/nonpublic/bookdb/";
my $csvdir = "/home/LIBRARY/ockerblo/bibdata/wikipedia/";
my $packagedir = "/home/LIBRARY/ockerblo/bookdb/packages/wikipedia/";
my $hathidir = "/home/LIBRARY/ockerblo/bookdb/packages/hathitrust/";

my $bookdir = "/home/LIBRARY/ockerblo/bookdb/";

my $wikiprod  = "wikidata";

my $minwpfilesize = "90000";
my $maxwpfilesize = "900000";

my $mincsvfilesize = "9000000";
my $maxcsvfilesize = "20000000";

my $minarticlefilesize = "1600000";
my $maxarticlefilesize = "3000000";

my $minhathifilesize = "9000000";
my $maxhathifilesize = "20000000";

my $minbookfilesize = "10000000";
my $maxbookfilesize = "30000000";

my $csvprod   = "wikiperiodicals.csv";

my $acsvprod  = "articleperiodicals.csv";

my $hcsvprod  = "wikihathioclcserials.csv";

my $bcsvprod  = "bookwikiids.csv";

$COPYRIGHT_ID_QUERY = qq!SELECT ?olbpid ?wikidataid ?article 
       (group_concat(?issn) as ?issns)
WHERE
  {?wikidataid wdt:P5396 ?olbpid .
  OPTIONAL {?article schema:about ?wikidataid .
            ?article schema:inLanguage "en" .
            ?article schema:isPartOf <https://en.wikipedia.org/> }
  OPTIONAL {?wikidataid wdt:P236 ?issn}
}
GROUP BY ?olbpid ?wikidataid ?article
ORDER BY ?olbpid
!;

$ISSN_QUERY = qq!SELECT ?wikidataid ?olbpid ?article ?start ?end
(group_concat(?issn) as ?issns)
WHERE
{
  {?wikidataid wdt:P236 ?issn} UNION {?wikidataid wdt:P5396 ?olbpid} .
  OPTIONAL {?article schema:about ?wikidataid .
            ?article schema:inLanguage "en" .
            ?article schema:isPartOf <https://en.wikipedia.org/> }
  OPTIONAL {?wikidataid wdt:P5396 ?olbpid}
  OPTIONAL {?wikidataid wdt:P571 ?start}
  OPTIONAL {?wikidataid wdt:P576 ?end}
}
GROUP BY ?wikidataid ?article ?olbpid ?start ?end
ORDER BY ?wikidataid
LIMIT 200000
!;

$ARTICLE_QUERY = qq!SELECT DISTINCT ?id ?article ?idLabel ?idDescription
   ?startdate ?enddate ?olbpid
   (GROUP_CONCAT(DISTINCT ?issn; SEPARATOR=" ") as ?issns)
WHERE
{
  ?article schema:about ?id .
  ?article schema:inLanguage "en" .
  ?article schema:isPartOf <https://en.wikipedia.org/> .
  {?id wdt:P31/wdt:P279* wd:Q1002697}
   UNION       {?id wdt:P236 ?issn} .
  OPTIONAL {?id wdt:P5396 ?olbpid}
  OPTIONAL {?id wdt:P571 ?startdate}
  OPTIONAL {?id wdt:P576 ?enddate}
  OPTIONAL {?id wdt:P582 ?enddate}
  OPTIONAL {?id wdt:P2669 ?enddate}

  FILTER (BOUND(?olbpid) || YEAR(?startdate) < 1964).
  SERVICE wikibase:label
     { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en" }
}
GROUP BY ?id ?article ?olbpid ?startdate ?enddate
         ?idLabel ?idDescription
LIMIT 100000
!;

$BOOK_QUERY = qq!SELECT DISTINCT ?id ?article
WHERE
{
  ?article schema:about ?id .
  ?article schema:inLanguage "en" .
  ?article schema:isPartOf <https://en.wikipedia.org/> .
  ?id wdt:P31/wdt:P279* wd:Q7725634

  SERVICE wikibase:label
     { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en" }
}
GROUP BY ?id ?article
LIMIT 300000
!;

$HATHI_OCLC_QUERY = qq!SELECT ?wikidataid ?olbpid
(group_concat(?issn) as ?issns)
(group_concat(?hathiid) as ?hathiids)
(group_concat(?oclc) as ?oclcs)
WHERE
{
   wd:Q2217301 ^wdt:P279*/^wdt:P31 ?wikidataid .
  OPTIONAL {?wikidataid wdt:P236 ?issn}
  OPTIONAL {?wikidataid wdt:P1844 ?hathiid}
  OPTIONAL {?wikidataid wdt:P5396 ?olbpid}
  OPTIONAL {?wikidataid wdt:P243 ?oclc}

  FILTER (BOUND(?olbpid) || BOUND(?hathiid) || BOUND(?issn) || BOUND(?oclc))

}
GROUP BY ?wikidataid ?olbpid
ORDER BY ?wikidataid
LIMIT 200000
!;
 
sub packhashtofile {
  my ($name, $hashref) = @_;
  my $hash = new OLBP::Hash(name=>$name, filename=>$name);
  return $hash->pack_to_file(hash=>$hashref);
}

sub make_idhash {
  my ($json) = @_;
  my $hash = {};
  return undef if (!$json);
  my $results = $json->{results};
  return undef if (!$results);
  my $bindings = $results->{bindings};
  return undef if (!$bindings);
  foreach my $binding (@{$bindings}) {
    my $olbpid = "";
    my $wdid = "";
    my $wparticle = "";
    if ($binding->{olbpid}) {
      $olbpid = $binding->{olbpid}->{value};
    }
    if ($binding->{wikidataid}) {
      $wdid = $binding->{wikidataid}->{value};
    }
    if ($binding->{article}) {
      $wparticle = $binding->{article}->{value};
    }
    if ($olbpid && $wdid) {
      $wdid =~ s/(.*)\///;          # remove path components
      $hash->{$olbpid} = "$wdid";
      if ($wparticle) {
        $hash->{$olbpid} .= " $wparticle";
      }
    }
  }
  return $hash;
}

sub do_hathi_query {
  my ($querier) = @_;
  print "Doing a Hathitrust query\n";
  my $path = "$hathidir$hcsvprod";
  $querier->write_managed_query(
    query=>$HATHI_OCLC_QUERY, format=>"csv", path=>$path,
    min=>$minhathifilesize, max=>$maxhathifilesize);
}

sub do_book_query {
  my ($querier) = @_;
  print "Doing a book query\n";
  my $path = "$bookdir$bcsvprod";
  $querier->write_managed_query(
    query=>$BOOK_QUERY, format=>"csv", path=>$path,
    min=>$minbookfilesize, max=>$maxbookfilesize);
}

sub do_issn_query {
  my ($querier) = @_;
  my $csvpath = "$csvdir$csvprod";
  if (!$querier->write_managed_query(
       query=>$ISSN_QUERY, format=>"csv", path=>$csvpath,
       min=>$mincsvfilesize, max=>$maxcsvfilesize)) {
    exit 0;
  }
}

sub do_article_query {
  my ($querier) = @_;
  my $newpath = "$packagedir$acsvprod";
  if (!$querier->write_managed_query(
       query=>$ARTICLE_QUERY, format=>"csv", path=>$newpath,
        min=>$minarticlefilesize, max=>$maxarticlefilesize)) {
    print "Something went wrong with the article query\n";
    exit 0;
  }
}

sub hashify {
  my ($file, $result) = @_;
  my $data = JSON::decode_json($result);
  my $idhash = make_idhash($data);
  packhashtofile($file, $idhash);
}

sub do_default_queries {
  my ($querier) = @_;
  my $newpath = "$idxdir$wikiprod.hsh";
  if (!$querier->write_managed_query(
       query=>$COPYRIGHT_ID_QUERY, format=>"json", path=>$newpath,
       transformer=>\&hashify,
       min=>$minwpfilesize, max=>$maxwpfilesize)) {
    print "Something went wrong with the copyright ID query\n";
    exit 0;
  }
  do_issn_query($querier);
  do_article_query($querier);
}

my $querier = new WikidataQuerier;

if ($ARGV[0] eq "hathi") {
  do_hathi_query($querier);
  exit 0;
}
if ($ARGV[0] eq "book") {
  do_book_query($querier);
  exit 0;
}

do_default_queries($querier);
